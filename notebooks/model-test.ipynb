{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38664bittfgpu0edc226f184a4684901072b5de47f5d3",
   "display_name": "Python 3.8.6 64-bit ('tf-gpu')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "import tensorflow.keras as tfk\n",
    "from transformers import TFGPT2LMHeadModel, GPT2TokenizerFast\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('../model/en_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_corpus_tokenizer = Tokenizer.from_file('../model/oscar-corpus-tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "oscar_corpus_tokenizer.get_vocab_size()"
   ]
  },
  {
   "source": [
    "### Load gpt2 model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained('../model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(model.transformer.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.stop_gradient(model.transformer.get_input_embeddings().weight.value()).numpy()"
   ]
  },
  {
   "source": [
    "## Create new embedding matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We need to get the mean embedding first as initial value for tokens that are not in the old vocab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "mean_weights = tf.reduce_mean(weights, axis = 0).numpy()\n",
    "mean_weights.shape"
   ]
  },
  {
   "source": [
    "Create new embedding matrix with new vocab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = oscar_corpus_tokenizer.get_vocab()\n",
    "old_vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "new_embeddings = tf.zeros([len(new_vocab), mean_weights.shape[0]]).numpy()\n",
    "new_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/50257 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33222d9aba664d969da2b382dd4aea73"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "in_en_vocab = []\n",
    "not_in_en_vocab = []\n",
    "for word, idx_new  in tqdm(new_vocab.items()):\n",
    "    idx_old =  old_vocab.get(word, -1)\n",
    "\n",
    "    if idx_old >= 0:\n",
    "        new_embeddings[idx_new, :] = weights[idx_old, :]\n",
    "        in_en_vocab.append(word)\n",
    "    else:\n",
    "        new_embeddings[idx_new, :] = mean_weights\n",
    "        not_in_en_vocab.append(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10244\n40013\n"
     ]
    }
   ],
   "source": [
    "print(len(in_en_vocab))\n",
    "print(len(not_in_en_vocab))"
   ]
  },
  {
   "source": [
    "set new embeddings "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.set_input_embeddings(tf.constant(new_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_corpus_tokenizer.enable_padding()\n",
    "inputs = oscar_corpus_tokenizer.encode_batch(['naunsa naman ka diha?', 'okay ra ka?'])\n",
    "inputs = np.array([i.ids for i in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 50257), dtype=float32, numpy=\n",
       "array([[[ -34.42376 ,  -33.993847,  -33.56087 , ...,  -39.639835,\n",
       "          -40.578823,  -40.578823],\n",
       "        [-109.75688 , -108.54434 , -108.19703 , ..., -113.4416  ,\n",
       "         -115.05064 , -115.05064 ],\n",
       "        [ -93.59099 ,  -91.837746,  -94.07659 , ..., -100.13715 ,\n",
       "         -100.39827 , -100.39827 ],\n",
       "        [-112.08247 , -111.186195, -111.84502 , ..., -118.42682 ,\n",
       "         -118.531456, -118.531456],\n",
       "        [ -96.70638 ,  -98.734085,  -99.56179 , ..., -105.150246,\n",
       "         -105.75707 , -105.75707 ]],\n",
       "\n",
       "       [[ -36.31277 ,  -34.806576,  -35.164993, ...,  -41.10214 ,\n",
       "          -42.398705,  -42.398705],\n",
       "        [ -81.05285 ,  -80.31885 ,  -80.06083 , ...,  -87.19076 ,\n",
       "          -87.26317 ,  -87.26317 ],\n",
       "        [ -80.86438 ,  -77.07138 ,  -79.10552 , ...,  -85.11696 ,\n",
       "          -87.3448  ,  -87.3448  ],\n",
       "        [ -96.84128 ,  -98.45837 ,  -98.81676 , ..., -104.71257 ,\n",
       "         -106.112885, -106.112885],\n",
       "        [ -93.81322 ,  -92.033745,  -85.15063 , ..., -103.2626  ,\n",
       "         -100.825584, -100.825584]]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "result = model(inputs)\n",
    "result.logits"
   ]
  },
  {
   "source": [
    "test predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
       "array([[   12, 22996,    13,   362,   199],\n",
       "       [   12,   326,    31,   199,    33]])>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "foo = tf.nn.softmax(logits=result.logits, axis = 2)\n",
    "tf.argmax(foo, axis = 2)"
   ]
  },
  {
   "source": [
    "### Freezing weights for fine tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For this implementation, only freeze the inner layers. Do not freeze layer norm, wte, and wpe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "def freeze_weights_vanilla(model):\n",
    "    for layer in model.transformer.h:\n",
    "        layer.trainable = False\n",
    "    model.transformer.wte.trainable = True\n",
    "    model.transformer.wpe.trainable = True\n",
    "    model.transformer.ln_f.trainable = True\n",
    "    \n",
    "# check if all are frozen\n",
    "freeze_weights_vanilla(model)\n",
    "all([not l.trainable for l in model.transformer.h])\n"
   ]
  },
  {
   "source": [
    "### train-test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd20ae82ee16440da0d2d25d08c42cf2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            document\n",
       "0  matamwa lg ko mayung gabe sa tanan....balikbay...\n",
       "1  Maayong kaagahon liwat diri sa payag ICCC...na...\n",
       "2  tani ari si pre idol toto jericp SR, para siya...\n",
       "3  Kapital sa munisipyo ang Āmol (Pinulongang Per...\n",
       "4  ↑ Kalkulado gikan sa pakigbingkil sa tanan nga..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>matamwa lg ko mayung gabe sa tanan....balikbay...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Maayong kaagahon liwat diri sa payag ICCC...na...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tani ari si pre idol toto jericp SR, para siya...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kapital sa munisipyo ang Āmol (Pinulongang Per...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>↑ Kalkulado gikan sa pakigbingkil sa tanan nga...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "text_lines = []\n",
    "with open('../shuff-dedup/ceb/ceb_dedup.txt', 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        text_lines.append(line)\n",
    "df_txt = pd.DataFrame({'document': text_lines})\n",
    "df_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessData(ids):\n",
    "    docs = df_txt.iloc[ids,:].document.tolist()    \n",
    "    encoded = oscar_corpus_tokenizer.encode_batch(docs)\n",
    "    x = np.array([i.ids for i in encoded])\n",
    "    attn_mask = np.array([i.attention_mask for  i in encoded])\n",
    "\n",
    "    return x, attn_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = sum(1 for line in open('../shuff-dedup/ceb/ceb_dedup.txt'))\n",
    "train_split = 0.8\n",
    "train_num_docs = int(num_lines * train_split)\n",
    "train_ids = np.random.choice(num_lines, train_num_docs, replace = False)\n",
    "test_ids = np.setdiff1d(np.arange(num_lines), train_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "60176\n15044\n"
     ]
    }
   ],
   "source": [
    "print(train_ids.shape[0])\n",
    "print(test_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "df_train = Dataset.from_tensor_slices(train_ids)\n",
    "df_train = df_train.shuffle(10000).batch(train_batch_size)\n",
    "df_train = df_train.map(lambda x: tf.py_function(PreprocessData, [x], [tf.int32, tf.int32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8, 131)\n(8, 131)\n"
     ]
    }
   ],
   "source": [
    "foo = list(df_train.take(1))\n",
    "for cmp in foo[0]:\n",
    "    print(cmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[TensorShape([768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768, 2304]),\n",
       " TensorShape([1, 2304]),\n",
       " TensorShape([768, 768]),\n",
       " TensorShape([1, 768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768, 3072]),\n",
       " TensorShape([1, 3072]),\n",
       " TensorShape([3072, 768]),\n",
       " TensorShape([1, 768])]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "[i.shape for i in model.transformer.h[0].variables]"
   ]
  },
  {
   "source": [
    "## Training routine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}