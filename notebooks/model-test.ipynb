{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38664bittfgpu0edc226f184a4684901072b5de47f5d3",
   "display_name": "Python 3.8.6 64-bit ('tf-gpu')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from transformers import TFGPT2LMHeadModel, GPT2TokenizerFast\n",
    "from tokenizers import Tokenizer\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('../model/en_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_corpus_tokenizer = Tokenizer.from_file('../model/oscar-corpus-tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "oscar_corpus_tokenizer.get_vocab_size()"
   ]
  },
  {
   "source": [
    "### Load gpt2 model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2LMHeadModel.from_pretrained('../model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(model.transformer.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.stop_gradient(model.transformer.get_input_embeddings().weight.value()).numpy()"
   ]
  },
  {
   "source": [
    "## Create new embedding matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We need to get the mean embedding first as initial value for tokens that are not in the old vocab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mean_weights = tf.reduce_mean(weights, axis = 0).numpy()\n",
    "mean_weights.shape"
   ]
  },
  {
   "source": [
    "Create new embedding matrix with new vocab"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = oscar_corpus_tokenizer.get_vocab()\n",
    "old_vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "new_embeddings = tf.zeros([len(new_vocab), mean_weights.shape[0]]).numpy()\n",
    "new_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/50257 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3fadad6e23b482b8b149707d382bc5c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "in_en_vocab = []\n",
    "not_in_en_vocab = []\n",
    "for word, idx_new  in tqdm(new_vocab.items()):\n",
    "    idx_old =  old_vocab.get(word, -1)\n",
    "\n",
    "    if idx_old >= 0:\n",
    "        new_embeddings[idx_new, :] = weights[idx_old, :]\n",
    "        in_en_vocab.append(word)\n",
    "    else:\n",
    "        new_embeddings[idx_new, :] = mean_weights\n",
    "        not_in_en_vocab.append(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10244\n40013\n"
     ]
    }
   ],
   "source": [
    "print(len(in_en_vocab))\n",
    "print(len(not_in_en_vocab))"
   ]
  },
  {
   "source": [
    "set new embeddings "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.set_input_embeddings(tf.constant(new_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_corpus_tokenizer.enable_padding()\n",
    "inputs = oscar_corpus_tokenizer.encode_batch(['naunsa naman ka diha?', 'okay ra ka?'])\n",
    "inputs = np.array([i.ids for i in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(inputs)"
   ]
  },
  {
   "source": [
    "test predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
       "array([[   12, 22996,    13,   362,   199],\n",
       "       [   12,   326,    31,   199,    33]])>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "foo = tf.nn.softmax(logits=result.logits, axis = 2)\n",
    "tf.argmax(foo, axis = 2)"
   ]
  },
  {
   "source": [
    "### Freezing weights for fine tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For this implementation, only freeze the inner layers. Do not freeze layer norm, wte, and wpe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "def freeze_weights_vanilla(model):\n",
    "    for layer in model.transformer.h:\n",
    "        layer.trainable = False\n",
    "    model.transformer.wte.trainable = True\n",
    "    model.transformer.wpe.trainable = True\n",
    "    model.transformer.ln_f.trainable = True\n",
    "    \n",
    "# check if all are frozen\n",
    "freeze_weights_vanilla(model)\n",
    "all([not l.trainable for l in model.transformer.h])\n"
   ]
  },
  {
   "source": [
    "### train-test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[TensorShape([768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768, 2304]),\n",
       " TensorShape([1, 2304]),\n",
       " TensorShape([768, 768]),\n",
       " TensorShape([1, 768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768]),\n",
       " TensorShape([768, 3072]),\n",
       " TensorShape([1, 3072]),\n",
       " TensorShape([3072, 768]),\n",
       " TensorShape([1, 768])]"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "[i.shape for i in model.transformer.h[0].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}